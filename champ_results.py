from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.hooks.postgres_hook import PostgresHook
from airflow.utils.dates import days_ago
from datetime import datetime, timedelta
import json
import requests
import logging
import time
import os

def load_championship_results():
    file_path = '/opt/airflow/dags/championships_data.json'
    base_url = "https://open.faceit.com/data/v4/championships/{champ_id}/results"
    api_key = '3f7d70c4-f8ca-42c9-98cb-3d1bdcc34ba7'
    headers = {'Authorization': f'Bearer {api_key}'}

    if not os.path.exists(file_path):
        logging.warning("–§–∞–π–ª championships_data.json –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return

    with open(file_path, 'r') as f:
        championship_ids = json.load(f)

    hook = PostgresHook(postgres_conn_id='Postgres_ROZA')
    conn = hook.get_conn()
    cursor = conn.cursor()

    insert_query = """
        INSERT INTO championship_results (
            championship_id,
            team_id,
            team_name,
            team_type,
            placement_range,
            loaded_at
        ) VALUES (%s, %s, %s, %s, %s, %s)
        ON CONFLICT DO NOTHING;
    """

    for idx, champ_id in enumerate(championship_ids):
        offset = 0
        limit = 100
        has_more = True
        total_inserted = 0

        logging.info(f"‚ñ∂Ô∏è –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É —á–µ–º–ø–∏–æ–Ω–∞—Ç–∞ {champ_id}")

        while has_more:
            url = f"{base_url.format(champ_id=champ_id)}?offset={offset}&limit={limit}"

            try:
                response = requests.get(url, headers=headers, timeout=10)
                response.raise_for_status()
                data = response.json()

                items = data.get("items", [])
                if not items:
                    logging.warning(f"‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —á–µ–º–ø–∏–æ–Ω–∞—Ç–∞: {champ_id} ‚Äî –≤—Å—Ç–∞–≤–ª—è–µ–º NULL-—Å—Ç—Ä–æ–∫—É.")
                    cursor.execute(insert_query, (
                        champ_id,
                        None,
                        None,
                        None,
                        None,
                        datetime.now().date()
                    ))
                    total_inserted += 1
                    break  # –ü—Ä–µ—Ä—ã–≤–∞–µ–º —Ü–∏–∫–ª, —Ç–∞–∫ –∫–∞–∫ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —á–µ–º–ø–∏–æ–Ω–∞—Ç–∞ –Ω–µ—Ç

                for item in items:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ –º–µ—Å—Ç–∞—Ö
                    left = item.get("bounds", {}).get("left")
                    right = item.get("bounds", {}).get("right")
                    placement_range = f"{left}" if left == right else f"{left}-{right}"

                    # –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º –≤—Å–µ –∫–æ–º–∞–Ω–¥—ã –≤ placements
                    placements = item.get("placements", [])
                    for placement in placements:
                        team_id = placement.get("id")
                        team_name = placement.get("name")
                        team_type = placement.get("type")

                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–æ–º–∞–Ω–¥–∞ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –ø—Ä–µ–∂–¥–µ —á–µ–º –≤—Å—Ç–∞–≤–∏—Ç—å –≤ –±–∞–∑—É
                        if team_id and team_name:
                            cursor.execute(insert_query, (
                                champ_id,
                                team_id,
                                team_name,
                                team_type,
                                placement_range,
                                datetime.now().date()
                            ))
                            total_inserted += 1

                has_more = len(items) == limit
                offset += limit
                time.sleep(0.3)

            except Exception as e:
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {champ_id} (offset={offset}): {e}")
                break

        logging.info(f"[{idx+1}/{len(championship_ids)}] ‚úÖ –ß–µ–º–ø–∏–æ–Ω–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω: {champ_id}, –≤—Å—Ç–∞–≤–ª–µ–Ω–æ: {total_inserted} —Å—Ç—Ä–æ–∫")

    conn.commit()
    cursor.close()
    conn.close()
    logging.info("üèÅ –í—Å–µ —á–µ–º–ø–∏–æ–Ω–∞—Ç—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")



# === DAG definition ===
default_args = {
    'owner': 'airflow',
    'retries': 2,
    'retry_delay': timedelta(minutes=3),
}

with DAG(
    dag_id='load_championship_results',
    description='–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —á–µ–º–ø–∏–æ–Ω–∞—Ç–æ–≤ FACEIT –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö',
    schedule_interval=None,
    start_date=days_ago(1),
    catchup=False,
    default_args=default_args,
    tags=['faceit', 'championships']
) as dag:

    load_results = PythonOperator(
        task_id='load_championship_results',
        python_callable=load_championship_results,
        execution_timeout=timedelta(hours=1),
    )
